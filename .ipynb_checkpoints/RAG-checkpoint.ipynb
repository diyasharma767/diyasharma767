{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 18) (__init__.py, line 18)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3505\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\n\u001b[1;33m    from langchain_community.document_loaders import TextLoader\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\document_loaders\\__init__.py:18\u001b[1;36m\u001b[0m\n\u001b[1;33m    The error you're encountering (ModuleNotFoundError: No module named 'pwd') is likely due to running the code on a Windows system. The pwd module is typically available on Unix-like systems (Linux, macOS) but not on Windows.from langchain_community.document_loaders.acreom import AcreomLoader\u001b[0m\n\u001b[1;37m                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 18)\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "loader=TextLoader(\"./PYTHON.txt\")\n",
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1116, which is longer than the specified 1000\n",
      "Created a chunk of size 1409, which is longer than the specified 1000\n",
      "Created a chunk of size 1088, which is longer than the specified 1000\n",
      "Created a chunk of size 1444, which is longer than the specified 1000\n",
      "Created a chunk of size 1386, which is longer than the specified 1000\n",
      "Created a chunk of size 1828, which is longer than the specified 1000\n",
      "Created a chunk of size 1911, which is longer than the specified 1000\n",
      "Created a chunk of size 1764, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter=CharacterTextSplitter(chunk_size=1000,chunk_overlap=4)\n",
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "try:\n",
    "        # Try to load the existing index\n",
    "        docsearch = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "except:\n",
    "        # If the index doesn't exist, create a new one\n",
    "        docsearch = FAISS.from_documents(docs, embeddings)\n",
    "        # Save the index locally\n",
    "        docsearch.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Define the repo ID and connect to Mixtral model on Huggingface\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(\n",
    "  repo_id=repo_id, \n",
    "  model_kwargs={\"temperature\": 0.8, \"top_k\": 50}, \n",
    "  huggingfacehub_api_token=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a AI Assistant. These Human will ask you a questions about Python. \n",
    "Use following piece of context to answer the question. \n",
    "If you don't know the answer, just say you don't know. \n",
    "Keep the answer within 2 sentences and concise.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=template,\n",
    "    input_variable=['context',\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "rag_chain=(\n",
    "    {\"context\":docsearch.as_retriever(),\"question\":RunnablePassthrough()}\n",
    "    |prompt\n",
    "    |llm \n",
    "    |StrOutputParser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pwd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharacterTextSplitter\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceInstructEmbeddings\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceHub\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\document_loaders\\__init__.py:32\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m document_loaders\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# If not in interactive env, raise warning.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive_env():\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\document_loaders\\__init__.py:163\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morg_mode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredOrgModeLoader\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    151\u001b[0m     AmazonTextractPDFLoader,\n\u001b[0;32m    152\u001b[0m     MathpixPDFLoader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     UnstructuredPDFLoader,\n\u001b[0;32m    162\u001b[0m )\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpebblo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PebbloSafeLoader\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolars_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolarsDataFrameLoader\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpowerpoint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredPowerPointLoader\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\document_loaders\\pebblo.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpwd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhttp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPStatus\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pwd'"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Load documents\n",
    "        loader = TextLoader('./PYTHON.txt')\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Split documents\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=4)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Initialize embeddings\n",
    "        embeddings = HuggingFaceInstructEmbeddings()\n",
    "\n",
    "        # Load or create FAISS index\n",
    "        try:\n",
    "            docsearch = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "        except:\n",
    "            docsearch = FAISS.from_documents(docs, embeddings)\n",
    "            docsearch.save_local(\"faiss_index\")\n",
    "\n",
    "        # Define the repo ID and connect to Mixtral model on Huggingface\n",
    "        repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "        llm = HuggingFaceHub(\n",
    "            repo_id=repo_id, \n",
    "            model_kwargs={\"temperature\": 0.8, \"top_k\": 50}, \n",
    "            huggingfacehub_api_token=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "        )\n",
    "\n",
    "        # Define the prompt template\n",
    "        template = \"\"\"\n",
    "        You are an AI Assistant. The Human will ask you questions about Python. \n",
    "        Use the following piece of context to answer the question. \n",
    "        If you don't know the answer, just say you don't know. \n",
    "        Keep the answer within 2 sentences and concise.\n",
    "\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=['context', 'question']\n",
    "        )\n",
    "\n",
    "        # Define the RAG chain\n",
    "        self.rag_chain = (\n",
    "            {\"context\": docsearch.as_retriever(), \"question\": RunnablePassthrough()} \n",
    "            | prompt \n",
    "            | llm \n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def invoke(self, input):\n",
    "        return self.rag_chain.invoke(input)\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    bot = ChatBot()\n",
    "    user_query = input(\"Ask me anything: \")\n",
    "    result = bot.invoke(user_query)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# bot = ChatBot()\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# user_query = input(\"Ask me anything: \")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# result = bot.rag_chain.invoke(user_query)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "bot = ChatBot()\n",
    "user_query = input(\"Ask me anything: \")\n",
    "result = bot.rag_chain.invoke(user_query)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
